"""
Rank all the model tests in the analysis directory.
"""

from glob import glob
import matplotlib.pyplot as plt
import numpy as np
import torch
from utils.constants import (ANALYSIS_P, MAE, MSE, OUTPUT_MIN_X,
                             OUTPUT_MAX_MIN_DIFF, RESULTS_F)
from utils.hdf_read_and_write import read_hdf
from utils.model import Model
from utils.norm import min_max_denorm
from utils.path import delete_dir, make_dir
from utils.printing_and_logging import step_ri, title
from utils.shared_argparser_args import shared_argparser_args
from utils.terminate_with_message import terminate_with_message
from utils.torch_hdf_ds_loader import DSLoaderHDF


def rank_analysis_dir_parser(subparsers):
    """
    Example commands:
    python3 main.py rank_analysis_dir --filter global_v1
    """
    subparser = subparsers.add_parser(
        'rank_analysis_dir',
        help='rank all model analyses',
    )
    subparser.set_defaults(main=rank_analysis_dir)
    subparser.add_argument(
        '--filter',
        help='partial string to filter analysis directories by',
    )
    subparser.add_argument(
        '--use-mse',
        action='store_true',
        help='use MSE instead of MAE',
    )


def rank_analysis_dir(cli_args):
    title('Model test script')

    step_ri('Error')
    use_mse = cli_args['use_mse']
    if use_mse:
        print('Using MSE')
    else:
        print('Using MAE')

    step_ri('Grabbing all potential analysis directories')
    filter_str = cli_args['filter']
    if filter_str:
        print(f'Applying the filter `{filter_str}`')
    else:
        filter_str = ''
    dir_paths = glob(f'{ANALYSIS_P}/*{filter_str}*/{RESULTS_F}')
    print(f'Found a total of {len(dir_paths)}')

    step_ri('Looping through and grabbing HDF files')
    # 2D array with the columns of (error, tag and epoch)
    results = []
    for dir_path in dir_paths:
        # Read in the results generated by the `model_test` script
        data = read_hdf(dir_path)
        # Each table has the shape of (samples, training columns), so just take
        # the average for a simple comparison value
        mae = np.mean(data[MAE])
        mse = np.mean(data[MSE])
        # Parse out the [tag].[epoch] portion of the path for the second value
        results.append([mse if use_mse else mae, dir_path.split('/')[-2]])

    step_ri('Sorting the rankings')
    sorted_results = sorted(results, key=lambda pair: pair[0])

    step_ri('Rankings')
    for idx, (error, tag_and_epoch) in enumerate(sorted_results):
        print(f'{idx + 1}.', tag_and_epoch, error)
